{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f15b42a",
   "metadata": {},
   "source": [
    "\\begin{titlepage}\n",
    "\n",
    "% Photo of FS\n",
    "\\centering\n",
    "\\vspace{-40pt}\n",
    "\\includegraphics[width=0.8\\textwidth]{Frankfurt_School_Logo.jpg}\\par\n",
    "\\vspace{2.5cm}\n",
    "\n",
    "% Course\n",
    "{\\scshape\\huge Assignment 3 \\par}\n",
    "\\vspace{2.5cm}\n",
    "\n",
    "% Title\n",
    "{\\Huge\\bfseries Sparse Random Projection \\par}\n",
    "{\\scshape\\large Jan's birthday edition \\par}\n",
    "\n",
    "\\vspace{2cm} % If signature is taken might have to add space.\n",
    "\n",
    "\n",
    "{\\Large Yannik Suhre \\par}\n",
    "{\\Large Skyler MacGowan \\par}\n",
    "{\\Large Debasmita Dutta \\par}\n",
    "{\\Large Sebastian Sydow \\par}\n",
    "\\vspace{0.5cm}\n",
    "\n",
    "% Date\n",
    "\\vfill\n",
    "{\\large \\today\\par}\n",
    "\\end{titlepage}\n",
    "\n",
    "\n",
    "\\newpage\n",
    "\n",
    "\\hypersetup{linkcolor=black}\n",
    "\\tableofcontents\n",
    "\n",
    "\\newpage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c74575a",
   "metadata": {},
   "source": [
    "## The Johnson-Lindenstrauss Lemma\n",
    "The Johnson-Lindenstrauss (JL) Lemma is the math behind Euclidean Distance/Space; it is what proves the “approximate maintenance of distance between the data points in different dimensions” property to be true. The lemma states that a small set of points in a high-dimensional space can be embedded into a space of much lower dimension in such a way that distances between the points are nearly preserved. The function `johnson_lindenstrauss_min_dim` of [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.random_projection.johnson_lindenstrauss_min_dim.html)\n",
    "calculates the  minimum number of components *k*, i.e. the number of dimensions in which distances between \n",
    "the points are nearly preserved, by the following formula:\n",
    "\n",
    "$$\n",
    "k >= \\frac{4 * log(n\\_samples)} {(\\frac{\\epsilon^2}{2} - \\frac{\\epsilon^3}{3})}\n",
    "$$\n",
    "\n",
    "Nevertheless, this only holds if the *right* *k* dimensions are chosen and not just any *k* dimensions.\n",
    "\n",
    "The following outlines the key components of the JL Lemma and what they represent. \n",
    "\n",
    "- *k*: This represents the minimum number of dimensions to which the dataset can be reduced to without a substantive decrease in accuracy, down from the original *d* dimensions. This *k* is in effect the result obtained from the JL Lemma formula, based on the parameters provided thereto. \n",
    "- $\\epsilon$: This represents the error term. Namely, in the context of conducting random projections in Euclidean space it is the **approximate** distance that is maintained, i.e. there is some error involved during this process. Naturally, that error could result in either an increase or a decrease in the distance, which is portrayed by the inequality below. In this inequality, 1 represents the original distance, $\\epsilon$ represents the error the user is willing to accept (range from 0 to 1, with lower values indicating a lower tolerance for error), the superscript indicates that this inequality applies to Euclidean Space (and hence the L2 norm), the vectors prior to their transformation are portrayed by the middle term ($f(x_i) - f(x_j)$), while the outer terms represent the two possibilities for the vectors following their transformation, namely that they are either somewhat smaller or somewhat larger than their original versions.\n",
    "$$\n",
    "(1 - \\epsilon) ||x_i - x_j||^2 <= ||f(x_i) - f(x_j)||^2 <= (1 + \\epsilon) ||x_i - x_j||^2\n",
    "$$\n",
    "- *n_samples*: This refers to the number of observations in the dataset.\n",
    "\n",
    "**Note**: The number of dimensions is independent of the original number of features but instead depends on the size of the dataset: the larger the dataset, the higher is the minimal dimensionality of an eps-embedding.\n",
    "\n",
    "**Note**: In the context of dimensionality reduction, random projections are typically used when one is unable to reliably calculate the covariance matrix (due to data sparsity for example), whereas when the covariance can be reliably calculated then Principal Component Analysis (PCA) is used. Both PCA and random projections require the dataset to be in Euclidean Space in order to function properly (more on Euclidean Space below)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3ddbe5",
   "metadata": {},
   "source": [
    "# Euclidean Space/Data\n",
    "\n",
    "When a given dataset is said to be in \"Euclidean Space\", that means that the distance between the observations (as represented by vectors) in the dataset is linearly defined. Essentially, you can draw a line between each vector pair, and this line represents the distance between each pair. Distance, in turn, is a measure of similarity, with lesser distances indicating greater similarity and vice versa. When referring to \"similarity\" what we mean specifically is *direction*; vectors whose directions are alike are more similar to one another. \n",
    "\n",
    "How is one to know whether a given dataset is in Euclidean Space? Well essentially anything embedded in physical space could reliaby said to be in Euclidean Space, because in such circumstances one can draw a line between two points and trust that that accurately represents the distance or similarity between them. In a geographical context for example, the distance *as the crow flies* between the Frankfurt School to the Abdeen Palace Museum in Cairo is 2,922.37 km whereas that between the Frankfurt School and the Church of the Holy Sepulchre in Jurusalem is 2,993.46 km; these are examples of euclidean distances, and from them we can determine that Frankfurt School is 71.12 km closer to the Abdeen Palace Museum than it is to the Church of the Holy Sepulchre. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940fbb1a",
   "metadata": {},
   "source": [
    "# Non-Euclidean Space/Data\n",
    "\n",
    "In Non-Euclidean Space, the \"linearity\" property described above in reference to Euclidean Space does not hold; one cannot simply draw a line between the constituent vector pairs and trust that this is an accurate measure of the similarity thereof (it isn't). Instead, in non-euclidean spaces the degree of similarity of the vectors should be measured using another (non-linear) scale, e.g. logarithmic, exponential, etc. \n",
    "\n",
    "For example, we define the loudness of a given sound via the decibel (dB) measure. In this measure, an increase of three decibals corresponds to a doubling of the overall loudness. Another fairly well-known example would be the moment-magnitude scale, which is the principal measure now used when assessing the strength and destructive potential of earthquakes. This scale goes from one to ten, with each step representing a 32 times larger release of energy than the preceeding step. For example, a 8.0 earthquake (\"Great\", occurs roughly once a year) releases 31622.776 times as much energy as does a 5.0 earthquake (\"Moderate\", occurs roughly 1250 times per year).\n",
    "\n",
    "United States Geographical Survey Earthquake Magnitude Comparison Calculator: https://earthquake.usgs.gov/education/calculator.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "989b670a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random projections of high-dimensional data\n",
    "# for database example: digits\n",
    "# Jan Nagler (adapted, Rosebrock), April 21\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from RandomProjectionClass import RandomSparseRepresentation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21487dd",
   "metadata": {},
   "source": [
    "# What are the datasets we recommed?\n",
    "1. @Debasmita https://archive.ics.uci.edu/ml/datasets/Urban+Land+Cover\n",
    "\n",
    "\n",
    "We will meet tmrw evening and until then everybody looks into the writing and looks a bit into the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f81d366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Welcome to the interface of **RandomSparseRepresentation**! :)\n",
       "        \n",
       "You have now instantiated an object, with which you can create a RandomSparseRepresentation.\n",
       "In order to do so, please first pick a dataset from this website [UCI ML](https://archive.ics.uci.edu/ml/index.php).\n",
       "\n",
       "Once you have done so, please use the function ```get_data()``` on your object to download that data. \n",
       "This function takes one necessary parameter and an optional one. The necessary one is the URL to\n",
       "the dataset you obtain when you right click in the data folder on the dataset and copy that link.\n",
       "Should the dataset not be a `.csv` within the datafolder on the UCI website, but rather a `.data`\n",
       "please also provide the column names as a list, which you can find in the `.names` file in the datafolder."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = RandomSparseRepresentation(birthday_version=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adea2d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "You successfully downloaded your dataset to the object!\n",
       "\n",
       "Now we can go ahead and split the data.\n",
       "Please call the `split_data()` function for it. You can pass it the `test_size` parameter, to split your\n",
       "data into test and train sets, the default value is `0.3`. Here are the first 5 rows of our data:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MFCCs_ 1</th>\n",
       "      <th>MFCCs_ 2</th>\n",
       "      <th>MFCCs_ 3</th>\n",
       "      <th>MFCCs_ 4</th>\n",
       "      <th>MFCCs_ 5</th>\n",
       "      <th>MFCCs_ 6</th>\n",
       "      <th>MFCCs_ 7</th>\n",
       "      <th>MFCCs_ 8</th>\n",
       "      <th>MFCCs_ 9</th>\n",
       "      <th>MFCCs_10</th>\n",
       "      <th>...</th>\n",
       "      <th>MFCCs_17</th>\n",
       "      <th>MFCCs_18</th>\n",
       "      <th>MFCCs_19</th>\n",
       "      <th>MFCCs_20</th>\n",
       "      <th>MFCCs_21</th>\n",
       "      <th>MFCCs_22</th>\n",
       "      <th>Family</th>\n",
       "      <th>Genus</th>\n",
       "      <th>Species</th>\n",
       "      <th>RecordID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.152936</td>\n",
       "      <td>-0.105586</td>\n",
       "      <td>0.200722</td>\n",
       "      <td>0.317201</td>\n",
       "      <td>0.260764</td>\n",
       "      <td>0.100945</td>\n",
       "      <td>-0.150063</td>\n",
       "      <td>-0.171128</td>\n",
       "      <td>0.124676</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108351</td>\n",
       "      <td>-0.077623</td>\n",
       "      <td>-0.009568</td>\n",
       "      <td>0.057684</td>\n",
       "      <td>0.118680</td>\n",
       "      <td>0.014038</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.171534</td>\n",
       "      <td>-0.098975</td>\n",
       "      <td>0.268425</td>\n",
       "      <td>0.338672</td>\n",
       "      <td>0.268353</td>\n",
       "      <td>0.060835</td>\n",
       "      <td>-0.222475</td>\n",
       "      <td>-0.207693</td>\n",
       "      <td>0.170883</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.090974</td>\n",
       "      <td>-0.056510</td>\n",
       "      <td>-0.035303</td>\n",
       "      <td>0.020140</td>\n",
       "      <td>0.082263</td>\n",
       "      <td>0.029056</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.152317</td>\n",
       "      <td>-0.082973</td>\n",
       "      <td>0.287128</td>\n",
       "      <td>0.276014</td>\n",
       "      <td>0.189867</td>\n",
       "      <td>0.008714</td>\n",
       "      <td>-0.242234</td>\n",
       "      <td>-0.219153</td>\n",
       "      <td>0.232538</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050691</td>\n",
       "      <td>-0.023590</td>\n",
       "      <td>-0.066722</td>\n",
       "      <td>-0.025083</td>\n",
       "      <td>0.099108</td>\n",
       "      <td>0.077162</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.224392</td>\n",
       "      <td>0.118985</td>\n",
       "      <td>0.329432</td>\n",
       "      <td>0.372088</td>\n",
       "      <td>0.361005</td>\n",
       "      <td>0.015501</td>\n",
       "      <td>-0.194347</td>\n",
       "      <td>-0.098181</td>\n",
       "      <td>0.270375</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.136009</td>\n",
       "      <td>-0.177037</td>\n",
       "      <td>-0.130498</td>\n",
       "      <td>-0.054766</td>\n",
       "      <td>-0.018691</td>\n",
       "      <td>0.023954</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.087817</td>\n",
       "      <td>-0.068345</td>\n",
       "      <td>0.306967</td>\n",
       "      <td>0.330923</td>\n",
       "      <td>0.249144</td>\n",
       "      <td>0.006884</td>\n",
       "      <td>-0.265423</td>\n",
       "      <td>-0.172700</td>\n",
       "      <td>0.266434</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048885</td>\n",
       "      <td>-0.053074</td>\n",
       "      <td>-0.088550</td>\n",
       "      <td>-0.031346</td>\n",
       "      <td>0.108610</td>\n",
       "      <td>0.079244</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MFCCs_ 1  MFCCs_ 2  MFCCs_ 3  MFCCs_ 4  MFCCs_ 5  MFCCs_ 6  MFCCs_ 7  \\\n",
       "0       1.0  0.152936 -0.105586  0.200722  0.317201  0.260764  0.100945   \n",
       "1       1.0  0.171534 -0.098975  0.268425  0.338672  0.268353  0.060835   \n",
       "2       1.0  0.152317 -0.082973  0.287128  0.276014  0.189867  0.008714   \n",
       "3       1.0  0.224392  0.118985  0.329432  0.372088  0.361005  0.015501   \n",
       "4       1.0  0.087817 -0.068345  0.306967  0.330923  0.249144  0.006884   \n",
       "\n",
       "   MFCCs_ 8  MFCCs_ 9  MFCCs_10  ...  MFCCs_17  MFCCs_18  MFCCs_19  MFCCs_20  \\\n",
       "0 -0.150063 -0.171128  0.124676  ... -0.108351 -0.077623 -0.009568  0.057684   \n",
       "1 -0.222475 -0.207693  0.170883  ... -0.090974 -0.056510 -0.035303  0.020140   \n",
       "2 -0.242234 -0.219153  0.232538  ... -0.050691 -0.023590 -0.066722 -0.025083   \n",
       "3 -0.194347 -0.098181  0.270375  ... -0.136009 -0.177037 -0.130498 -0.054766   \n",
       "4 -0.265423 -0.172700  0.266434  ... -0.048885 -0.053074 -0.088550 -0.031346   \n",
       "\n",
       "   MFCCs_21  MFCCs_22           Family      Genus         Species  RecordID  \n",
       "0  0.118680  0.014038  Leptodactylidae  Adenomera  AdenomeraAndre         1  \n",
       "1  0.082263  0.029056  Leptodactylidae  Adenomera  AdenomeraAndre         1  \n",
       "2  0.099108  0.077162  Leptodactylidae  Adenomera  AdenomeraAndre         1  \n",
       "3 -0.018691  0.023954  Leptodactylidae  Adenomera  AdenomeraAndre         1  \n",
       "4  0.108610  0.079244  Leptodactylidae  Adenomera  AdenomeraAndre         1  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.get_data(\"./data/Frogs_MFCCs.csv\",\n",
    "              data_type = \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a94e1bb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The first thing we need to do, is to determine which of the columns shall be our target variable.\n",
       "Hence they are all printed out in the next step.\n",
       "\n",
       "['MFCCs_ 1', 'MFCCs_ 2', 'MFCCs_ 3', 'MFCCs_ 4', 'MFCCs_ 5', 'MFCCs_ 6', 'MFCCs_ 7', 'MFCCs_ 8', 'MFCCs_ 9', 'MFCCs_10', 'MFCCs_11', 'MFCCs_12', 'MFCCs_13', 'MFCCs_14', 'MFCCs_15', 'MFCCs_16', 'MFCCs_17', 'MFCCs_18', 'MFCCs_19', 'MFCCs_20', 'MFCCs_21', 'MFCCs_22', 'Family', 'Genus', 'Species', 'RecordID']\n",
       "\n",
       "In the next step please input a column name, which is contains your target variable."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please input your target variable here: Species\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Your data has now be splitted into a train and test set by a ratio of `0.3`.\n",
       "This was done, by selecting the column `Species` as target column and the rest as independent variables."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.split_data(standardize = False, columns_to_drop = [\"RecordID\", \"Family\", \"Genus\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da0561c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "In general, the theory of Professor Johnson and Professor Lindenstrauss posits\n",
       "the amount of columns to which we can reduce our dataset without losing any distance related information.\n",
       "We can specify a parameter called `epsilon` which determines the margin in which the distance is contained.\n",
       "\n",
       "Our current dataset has 7195 observations. Using the JL algorithm, we could reduce it to\n",
       "7612 dimensions."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The JL also works, if we have a smaller dataset... **Ask group**!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The next step is to set a define a baseline metric, on which we want to evaluate\n",
       "our algorithm with our later reduced dataset. For this please call the function `baseline()`."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.JL_lemma()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "222a0289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "In order to asses the performance of a classifier, it is important to incorporate a numerical evaluation of the algorithm. \n",
       "For this, a variety of performance measures are available. It is essential to make use of an adequate performance measure as \n",
       "their applicability and significance depend on the dataset as well as the specific classification task.\n",
       "There are a few metrics we can choose from, the needed API (which you need to input next) can be viewed\n",
       "[here](https://scikit-learn.org/stable/modules/model_evaluation.html). For the task at hand, the performance \n",
       "measures used are either *accuracy* or the $f_1$ *score*.\n",
       "\n",
       "$$\n",
       "Accuracy = \\frac{True\\ Positives + True\\ Negatives }{True\\ Positives + False\\ Positives + True\\ Negatives + False\\ Negatives}\n",
       "$$\n",
       "\n",
       "*Accuracy* measures the performance of a classification model as the number of correct \n",
       "predictions divided by the total number of predictions. Its main advantage is its easy interpretability. \n",
       "Nevertheless, *accuracy* should only be used for balanced datasets. When dealing with imbalanced datasets,\n",
       "i.e. when some classes are much more frequent than others, *accuracy* is not a reliable performance measure. \n",
       "\n",
       "$$\n",
       "f_1 = 2 * \\frac{Precision * Recall}{Precision + Recall}\n",
       "$$\n",
       "\n",
       "The $f_1$ Score is the harmonic mean of *precision* and *recall*, i.e. it applys equal weight to both. \n",
       "The $f_1$ Score represents a meaningful evaluation for imbalanced datasets. As such, we recommend to\n",
       "choose `accuracy_score` for balanced datasets and `f1_score` for imbalanced datasets.\n",
       "\n",
       "Additionally, for imbalanced datasets, i.e. situations in which the `f1_score` is chosen, the user should differentiate\n",
       "between binary and multi-class classification. For multi-class classification, the \n",
       "parameter *average* ought to be specified, as its default is only applicable if targets are\n",
       "[binary](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score).\n",
       "Four other parameter values are possible: *micro*, *macro*, *weighted* and *samples*. *Samples* is only \n",
       "meaningful for multilabel classification, which will not be in the scope of this assignment. Thus, we will \n",
       "only examine *micro*, *macro* and *weighted*. \n",
       "\n",
       "The *macro* $f_1$ *score* is computed as a simple arithmetic mean of the per-class $f_1$ *scores*. \n",
       "It does not take label imbalance into account.\n",
       "\n",
       "The *weighted* $f_1$ *score* alters *macro* to account for label imbalance. The weight is applied by \n",
       "the number of true instances for each label.\n",
       "\n",
       "The *micro* $f_1$ *score* is calculated counting the total true positives, false negatives and false positives.\n",
       "Thus, the *micro* $f_1$ *score* is equal to total number of true positives over the total number of all observations.\n",
       "Further explanations can be found\n",
       "[here](https://scikit-learn.org/stable/modules/model_evaluation.html#multiclass-and-multilabel-classification.).\n",
       "\n",
       "In conclusion, we recommend to chose `average = weighted` for the performance metric `f1_score` for the \n",
       "purpose of this assignment as this will account for the imbalance in the dataset. \n",
       "\n",
       "The chosen metric used for our baseline should be inputted in the following prompt. Be sure to insert it \n",
       "like `accuracy_score` if you want to use `accuracy_score` or respective for all other metrics."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please insert your metric here: f1_score\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "You have selected the `f1_score`. Since the `f1_score` can have different\n",
       "                usages as described earlier, depending on its inputs please input some keyword-arguments into\n",
       "                the next prompt.\n",
       "                Please be advised, that this is done via `average=\"binary\", ...`, meaning with a = as separator."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter your keyword arguments here: average=\"weighted\"\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Awesome, you have set your baseline! Now call the function `apply_random_projection` to check out,\n",
       "    how good your model performs when we reduce its dimensions."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.baseline(model = SVC, kernel='rbf', gamma = 0.1, C=5, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9eff403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "Random Projection is a dimensionality reduction technique which is based on the **Johnson-Lindenstrauss lemma**.\n",
       "This method projects or transforms the higher dimensional data to a lower dimensional subspace.\n",
       "It approximately preserves the pairwise distances of the data points. \n",
       "It uses a random matrix to perform the projection and hence the name random projection. \n",
       "This matrix is also sometimes refered to as map.\n",
       "\n",
       "If the original dimension of data is $d$ and the target or projected dimension is $k$, where $k<<d$ \n",
       "then the random matrix is of size $k X d$. The random projection can be explained as below\n",
       "\n",
       "$X_{kXN}^{RP}$ = $R_{kXd}$$X_{dXN}$\n",
       "\n",
       "Where\n",
       "\n",
       "$X_{kXN}^{RP}$ is the random projected N observations in k dimension.\n",
       "\n",
       "$R_{kXd}$ is the random matrix used for the projection or transformation.\n",
       "\n",
       "$X_{dXN}$ is the original N observations in d-dimension.\n",
       "\n",
       "There are few techniques to create the random matrix. Gaussian and Sparse are just 2 among them.\n",
       "\n",
       "**Gaussian** – The random matrix is created in such a way that each entry is independently drawn from\n",
       "the standard normal distribution $N(0, \\frac{1}{n_{components}})$. Where $n_{components} is the number of target dimension. \n",
       "\n",
       "**Sparse** – When a sparse matrix is used for the random projection to reduce the computational complexity, then this \n",
       "is a sparse projection. This is an alternate approach to Gaussian random projection matrix and \n",
       "ensures the similar distance preserving quality while reducing the dimension.\n",
       "\n",
       "If we define $s = 1 / density$, the elements of the random matrix are drawn from\n",
       "\n",
       "\\begin{equation}\n",
       "\\begin{split}\\left\\{\n",
       "\\begin{array}{c c l}\n",
       "-\\sqrt{\\frac{s}{n_{\\text{components}}}} & & 1 / 2s\\\\\n",
       "0 &\\text{with probability}  & 1 - 1 / s \\\\\n",
       "+\\sqrt{\\frac{s}{n_{\\text{components}}}} & & 1 / 2s\\\\\n",
       "\\end{array}\n",
       "\\right.\\end{split}\n",
       "\\end{equation}\n",
       "\n",
       "If the sparse projection matrix has $c$ nonzero entries per column, then the complexity of the operation \n",
       "is of order $O(ckN)$ instead of $O(dkN)$.\n",
       "\n",
       "Now we can apply our random projection onto our dataset, which we loaded earlier. Once that function is done\n",
       "you can head over to the next function which is called `plot`. That function will plot the baseline and your\n",
       "chosen metric over the different dimensions."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.apply_random_projection(model = SVC, kernel='rbf', gamma = 0.1, C=5, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cd74c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "dry_beans = RandomSparseRepresentation(text = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85e21748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please input your target variable here: Class\n",
      "Please insert your metric here: f1_score\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "You have selected the `f1_score`. Since the `f1_score` can have different\n",
       "                usages as described earlier, depending on its inputs please input some keyword-arguments into\n",
       "                the next prompt.\n",
       "                Please be advised, that this is done via `average=\"binary\", ...`, meaning with a = as separator."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter your keyword arguments here: average=\"weighted\"\n"
     ]
    }
   ],
   "source": [
    "# Plot explained variances\n",
    "dry_beans.prepare_fit(url = \"./data/Dry_Bean_Dataset.xlsx\", data_type = \".xlsx\",\n",
    "                     standardize = True,\n",
    "                     model = SVC, kernel='rbf', gamma = 0.1, C=5, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7b57a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize = (16,8))\n",
    "ax[0].set_ylim([0,1])\n",
    "ax[0].plot(data.dims, [data.baseline] * len(data.accuracies), color = \"r\")\n",
    "ax[0].plot(data.dims, data.accuracies)\n",
    "ax[0].set_title(\"Sparse Random Projection with Frog data\")\n",
    "ax[1].plot(dry_beans.dims, [dry_beans.baseline] * len(dry_beans.accuracies), color = \"r\")\n",
    "ax[1].plot(dry_beans.dims, dry_beans.accuracies)\n",
    "ax[1].set_title(\"Sparse Random Projection with Dry Beans Data\")\n",
    "ax[1].set_ylim([0,1])\n",
    "plt.show() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
